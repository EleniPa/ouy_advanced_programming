{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example of where I could have used assertions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = open(\"PeopleTrainingDateUpdate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'05/11/2018,diam.Duis.mi@fringillapurus.net 16200816-7450,,\"Hensley, Martina G.\",Nonummy Consulting\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file2.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into seperate strings in a list by comma, remove unnecessary characters\n",
    "entry_list = []\n",
    "for line in file2:\n",
    "    items = line.split(\",\")\n",
    "    stripped_items = []\n",
    "    for i in items:\n",
    "        stripped_items.append(i.replace('\"', \"\").replace(\"\\n\", \"\").replace(\".\", \"\").lstrip(\" \"))\n",
    "    entry_list.append(stripped_items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['28/11/2018',\n",
       "  'euismod@magnisdisparturientnet 16650329-8280',\n",
       "  'Mr',\n",
       "  'Flynn',\n",
       "  'Noelani S',\n",
       "  'Ac PC'],\n",
       " ['16/12/2018',\n",
       "  'etlibero@Proinnet 16501112-4038',\n",
       "  '',\n",
       "  'Mayo',\n",
       "  'Erich I',\n",
       "  'Quis Massa Mauris Institute'],\n",
       " ['17/12/2018',\n",
       "  'velit@Nullaeuedu 16630306-4247',\n",
       "  '',\n",
       "  'Lyons',\n",
       "  'Hedwig L',\n",
       "  'Duis Risus Odio Institute'],\n",
       " ['17/12/2018',\n",
       "  'magna@vulputaterisusaedu 16970522-2686',\n",
       "  'Mr',\n",
       "  'Wood',\n",
       "  'Leila P',\n",
       "  'Pharetra Sed Hendrerit PC'],\n",
       " ['19/12/2018',\n",
       "  'orci@dolorNullasemperca 16100930-7719',\n",
       "  '',\n",
       "  'Dodson',\n",
       "  'Kaseem M',\n",
       "  'Diam At LLP'],\n",
       " ['21/01/2019',\n",
       "  'nostra@infaucibusca 16880622-6034',\n",
       "  'Mr',\n",
       "  'Miranda',\n",
       "  'Hanna Z',\n",
       "  'Enim Mi Tempor Institute'],\n",
       " ['22/01/2019',\n",
       "  'duiFusce@eleifendnonorg 16120621-3389',\n",
       "  '',\n",
       "  'Tate',\n",
       "  'David D',\n",
       "  'Urna Corporation'],\n",
       " ['25/01/2019',\n",
       "  'ligulaDonec@laciniavitaeca 16820906-3364',\n",
       "  'Dr',\n",
       "  'Duncan',\n",
       "  'Cheyenne E',\n",
       "  'Sit Amet Corporation'],\n",
       " ['29/01/2019',\n",
       "  'orci@congueInedu 16790420-1873',\n",
       "  'Dr',\n",
       "  'Franks',\n",
       "  'Nissim L',\n",
       "  'Dictum Ultricies Ligula LLP'],\n",
       " ['29/01/2019',\n",
       "  'maurisSuspendisse@mollisca 16590729-1222',\n",
       "  'Mr',\n",
       "  'Heath',\n",
       "  'Keane U',\n",
       "  'Risus Consulting'],\n",
       " ['02/02/2019',\n",
       "  'lobortisrisusIn@tincidunttempusca 16051030-5139',\n",
       "  'Ms',\n",
       "  'Vincent',\n",
       "  'Grace Q',\n",
       "  'Ultrices A Auctor Associates'],\n",
       " ['25/02/2019',\n",
       "  'Sedeu@laciniaatiaculisca 16670401-6622',\n",
       "  'Dr',\n",
       "  'Mcdowell',\n",
       "  'Edward P',\n",
       "  'Integer Sem Limited'],\n",
       " ['28/02/2019',\n",
       "  'porttitoreros@seddoloredu 16100230-3863',\n",
       "  'Dr',\n",
       "  'Massey',\n",
       "  'Freya J',\n",
       "  'Eu Erat Semper Inc'],\n",
       " ['28/02/2019',\n",
       "  'egestasDuis@Nunccommodoauctorcouk 16160503-6332',\n",
       "  '',\n",
       "  'Yates',\n",
       "  'Gisela X',\n",
       "  'Fringilla Ornare Corporation'],\n",
       " ['13/03/2019',\n",
       "  'vehiculaPellentesque@anet 16970426-3707',\n",
       "  'Mrs',\n",
       "  'Coffey',\n",
       "  'Yvette W',\n",
       "  'Tellus Id Nunc LLC'],\n",
       " ['18/03/2019',\n",
       "  'eratvolutpatNulla@loremvitaeodionet 16620309-0201',\n",
       "  'Mrs',\n",
       "  'Gutierrez',\n",
       "  'Christopher B',\n",
       "  'Est Limited'],\n",
       " ['23/03/2019',\n",
       "  'Duis@dolorvitaedoloredu 16550814-4507',\n",
       "  'Mr',\n",
       "  'Wiggins',\n",
       "  'Tarik S',\n",
       "  'Neque Sed Limited'],\n",
       " ['23/03/2019',\n",
       "  'vitaeposuere@nonummyultriciesornarecom 16990315-8039',\n",
       "  'Mrs',\n",
       "  'Ray',\n",
       "  'Lucy G',\n",
       "  'Ante Ipsum Corp'],\n",
       " ['24/03/2019',\n",
       "  'bibendumfermentummetus@Donecfelisedu 16910207-2528',\n",
       "  'Mrs',\n",
       "  'Meyer',\n",
       "  'Gail D',\n",
       "  'Netus Et Malesuada Corp'],\n",
       " ['27/03/2019',\n",
       "  'venenatis@massaIntegervitaeorg 16950324-8800',\n",
       "  '',\n",
       "  'Rivers',\n",
       "  'Quin S',\n",
       "  'Semper Dui Lectus Limited'],\n",
       " ['29/03/2019',\n",
       "  'ipsumdolorsit@Maecenasmalesuadaedu 16510221-4797',\n",
       "  'Mr',\n",
       "  'Salazar',\n",
       "  'Camille D',\n",
       "  'Magnis Dis Parturient Associates']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visual check - different order: Updated, email+id, title, surname, first_name and initial\n",
    "entry_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HERE! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What i did originally: I knew that each entry a length of 7 first time around, need to check if consistent with that\n",
    "# check for consistency by length - all have same number of items\n",
    "#  but 1 less than first file as email and id are not comma seperated\n",
    "length_list = []\n",
    "for l in entry_list:\n",
    "    x = len(l)\n",
    "    length_list.append(x)\n",
    "\n",
    "length_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Lengths do not uniformly match at entry_list[0]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-a99aaf35fd0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Alternative approach\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentry_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"Lengths do not uniformly match at entry_list[{entry_list.index(l)}]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m: Lengths do not uniformly match at entry_list[0]"
     ]
    }
   ],
   "source": [
    "#Alternative approach\n",
    "for l in entry_list: \n",
    "    assert len(l) == 7, f\"Lengths do not uniformly match at entry_list[{entry_list.index(l)}]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in entry_list:\n",
    "    email_id = l[1].split(\" \")\n",
    "    l.remove(l[1])\n",
    "    l.extend(email_id)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['28/11/2018',\n",
       "  'Mr',\n",
       "  'Flynn',\n",
       "  'Noelani S',\n",
       "  'Ac PC',\n",
       "  'euismod@magnisdisparturientnet',\n",
       "  '16650329-8280'],\n",
       " ['16/12/2018',\n",
       "  '',\n",
       "  'Mayo',\n",
       "  'Erich I',\n",
       "  'Quis Massa Mauris Institute',\n",
       "  'etlibero@Proinnet',\n",
       "  '16501112-4038'],\n",
       " ['17/12/2018',\n",
       "  '',\n",
       "  'Lyons',\n",
       "  'Hedwig L',\n",
       "  'Duis Risus Odio Institute',\n",
       "  'velit@Nullaeuedu',\n",
       "  '16630306-4247'],\n",
       " ['17/12/2018',\n",
       "  'Mr',\n",
       "  'Wood',\n",
       "  'Leila P',\n",
       "  'Pharetra Sed Hendrerit PC',\n",
       "  'magna@vulputaterisusaedu',\n",
       "  '16970522-2686'],\n",
       " ['19/12/2018',\n",
       "  '',\n",
       "  'Dodson',\n",
       "  'Kaseem M',\n",
       "  'Diam At LLP',\n",
       "  'orci@dolorNullasemperca',\n",
       "  '16100930-7719'],\n",
       " ['21/01/2019',\n",
       "  'Mr',\n",
       "  'Miranda',\n",
       "  'Hanna Z',\n",
       "  'Enim Mi Tempor Institute',\n",
       "  'nostra@infaucibusca',\n",
       "  '16880622-6034'],\n",
       " ['22/01/2019',\n",
       "  '',\n",
       "  'Tate',\n",
       "  'David D',\n",
       "  'Urna Corporation',\n",
       "  'duiFusce@eleifendnonorg',\n",
       "  '16120621-3389'],\n",
       " ['25/01/2019',\n",
       "  'Dr',\n",
       "  'Duncan',\n",
       "  'Cheyenne E',\n",
       "  'Sit Amet Corporation',\n",
       "  'ligulaDonec@laciniavitaeca',\n",
       "  '16820906-3364'],\n",
       " ['29/01/2019',\n",
       "  'Dr',\n",
       "  'Franks',\n",
       "  'Nissim L',\n",
       "  'Dictum Ultricies Ligula LLP',\n",
       "  'orci@congueInedu',\n",
       "  '16790420-1873'],\n",
       " ['29/01/2019',\n",
       "  'Mr',\n",
       "  'Heath',\n",
       "  'Keane U',\n",
       "  'Risus Consulting',\n",
       "  'maurisSuspendisse@mollisca',\n",
       "  '16590729-1222'],\n",
       " ['02/02/2019',\n",
       "  'Ms',\n",
       "  'Vincent',\n",
       "  'Grace Q',\n",
       "  'Ultrices A Auctor Associates',\n",
       "  'lobortisrisusIn@tincidunttempusca',\n",
       "  '16051030-5139'],\n",
       " ['25/02/2019',\n",
       "  'Dr',\n",
       "  'Mcdowell',\n",
       "  'Edward P',\n",
       "  'Integer Sem Limited',\n",
       "  'Sedeu@laciniaatiaculisca',\n",
       "  '16670401-6622'],\n",
       " ['28/02/2019',\n",
       "  'Dr',\n",
       "  'Massey',\n",
       "  'Freya J',\n",
       "  'Eu Erat Semper Inc',\n",
       "  'porttitoreros@seddoloredu',\n",
       "  '16100230-3863'],\n",
       " ['28/02/2019',\n",
       "  '',\n",
       "  'Yates',\n",
       "  'Gisela X',\n",
       "  'Fringilla Ornare Corporation',\n",
       "  'egestasDuis@Nunccommodoauctorcouk',\n",
       "  '16160503-6332'],\n",
       " ['13/03/2019',\n",
       "  'Mrs',\n",
       "  'Coffey',\n",
       "  'Yvette W',\n",
       "  'Tellus Id Nunc LLC',\n",
       "  'vehiculaPellentesque@anet',\n",
       "  '16970426-3707'],\n",
       " ['18/03/2019',\n",
       "  'Mrs',\n",
       "  'Gutierrez',\n",
       "  'Christopher B',\n",
       "  'Est Limited',\n",
       "  'eratvolutpatNulla@loremvitaeodionet',\n",
       "  '16620309-0201'],\n",
       " ['23/03/2019',\n",
       "  'Mr',\n",
       "  'Wiggins',\n",
       "  'Tarik S',\n",
       "  'Neque Sed Limited',\n",
       "  'Duis@dolorvitaedoloredu',\n",
       "  '16550814-4507'],\n",
       " ['23/03/2019',\n",
       "  'Mrs',\n",
       "  'Ray',\n",
       "  'Lucy G',\n",
       "  'Ante Ipsum Corp',\n",
       "  'vitaeposuere@nonummyultriciesornarecom',\n",
       "  '16990315-8039'],\n",
       " ['24/03/2019',\n",
       "  'Mrs',\n",
       "  'Meyer',\n",
       "  'Gail D',\n",
       "  'Netus Et Malesuada Corp',\n",
       "  'bibendumfermentummetus@Donecfelisedu',\n",
       "  '16910207-2528'],\n",
       " ['27/03/2019',\n",
       "  '',\n",
       "  'Rivers',\n",
       "  'Quin S',\n",
       "  'Semper Dui Lectus Limited',\n",
       "  'venenatis@massaIntegervitaeorg',\n",
       "  '16950324-8800'],\n",
       " ['29/03/2019',\n",
       "  'Mr',\n",
       "  'Salazar',\n",
       "  'Camille D',\n",
       "  'Magnis Dis Parturient Associates',\n",
       "  'ipsumdolorsit@Maecenasmalesuadaedu',\n",
       "  '16510221-4797']]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# order is now: Updated, title, surname, first_name, company, email, id\n",
    "entry_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a for loop to create lists for each column\n",
    "title = []\n",
    "first_name = []\n",
    "surname = []\n",
    "i_d = []\n",
    "email = []\n",
    "company = []\n",
    "updated = []\n",
    "for l in entry_list:\n",
    "    title.append(l[1])\n",
    "    first_name.append(l[3])\n",
    "    surname.append(l[2])\n",
    "    i_d.append(l[6])\n",
    "    email.append(l[5])\n",
    "    company.append(l[4])\n",
    "    updated.append(l[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list comprehension to create one name variable from surname and first_name\n",
    "name = [x + \", \" + y for x,y in zip(surname, first_name)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict following same order as result_df_ex2, which this incoming data will be merged with\n",
    "title_column_dict_rearr = {cols[5]: updated, cols[0]: title, cols[1]: name, cols[2]: i_d, cols[3]: email, cols[4]: company}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_dataframe\n",
    "df_ex3 = pd.DataFrame(title_column_dict_rearr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with existing df\n",
    "dfs_to_merge = [result_df_ex2, df_ex3]\n",
    "result_df_ex3 = pd.concat(dfs_to_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert updated to datetime for sorting\n",
    "result_df_ex3['Updated'] = pd.to_datetime(result_df_ex3['Updated'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Updated</th>\n",
       "      <th>Title</th>\n",
       "      <th>Name</th>\n",
       "      <th>ID</th>\n",
       "      <th>Email</th>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01-04</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Nita Z, Clarke</td>\n",
       "      <td>16220630-3253</td>\n",
       "      <td>pharetraNam@egestashendreritnequecom</td>\n",
       "      <td>Aliquam Nec Enim Institute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2017-02-09</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Devin C, Goodman</td>\n",
       "      <td>16720911-1181</td>\n",
       "      <td>Maecenas@sociisnatoquepenatibuscom</td>\n",
       "      <td>Elementum Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-04-05</td>\n",
       "      <td>Ms</td>\n",
       "      <td>Zena K, Martin</td>\n",
       "      <td>16750216-5116</td>\n",
       "      <td>Namnullamagna@massaIntegervitaecom</td>\n",
       "      <td>Volutpat Nulla Corp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-14</td>\n",
       "      <td></td>\n",
       "      <td>Lenore G, Cobb</td>\n",
       "      <td>16190501-6752</td>\n",
       "      <td>ullamcorperDuiscursus@vehiculaetrutrumedu</td>\n",
       "      <td>Turpis Egestas Aliquam Ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-27</td>\n",
       "      <td>Ms</td>\n",
       "      <td>Naomi J, Burris</td>\n",
       "      <td>16010323-3201</td>\n",
       "      <td>ametanteVivamus@arcuacorcicom</td>\n",
       "      <td>A Malesuada Associates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-03-23</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Wiggins, Tarik S</td>\n",
       "      <td>16550814-4507</td>\n",
       "      <td>Duis@dolorvitaedoloredu</td>\n",
       "      <td>Neque Sed Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-03-23</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Ray, Lucy G</td>\n",
       "      <td>16990315-8039</td>\n",
       "      <td>vitaeposuere@nonummyultriciesornarecom</td>\n",
       "      <td>Ante Ipsum Corp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-03-24</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Meyer, Gail D</td>\n",
       "      <td>16910207-2528</td>\n",
       "      <td>bibendumfermentummetus@Donecfelisedu</td>\n",
       "      <td>Netus Et Malesuada Corp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-03-27</td>\n",
       "      <td></td>\n",
       "      <td>Rivers, Quin S</td>\n",
       "      <td>16950324-8800</td>\n",
       "      <td>venenatis@massaIntegervitaeorg</td>\n",
       "      <td>Semper Dui Lectus Limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2019-03-29</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Salazar, Camille D</td>\n",
       "      <td>16510221-4797</td>\n",
       "      <td>ipsumdolorsit@Maecenasmalesuadaedu</td>\n",
       "      <td>Magnis Dis Parturient Associates</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Updated Title                Name             ID  \\\n",
       "0  2017-01-04    Mr      Nita Z, Clarke  16220630-3253   \n",
       "25 2017-02-09    Mr    Devin C, Goodman  16720911-1181   \n",
       "4  2017-04-05    Ms      Zena K, Martin  16750216-5116   \n",
       "1  2017-04-14            Lenore G, Cobb  16190501-6752   \n",
       "2  2017-04-27    Ms     Naomi J, Burris  16010323-3201   \n",
       "..        ...   ...                 ...            ...   \n",
       "16 2019-03-23    Mr    Wiggins, Tarik S  16550814-4507   \n",
       "17 2019-03-23   Mrs         Ray, Lucy G  16990315-8039   \n",
       "18 2019-03-24   Mrs       Meyer, Gail D  16910207-2528   \n",
       "19 2019-03-27            Rivers, Quin S  16950324-8800   \n",
       "20 2019-03-29    Mr  Salazar, Camille D  16510221-4797   \n",
       "\n",
       "                                        Email  \\\n",
       "0        pharetraNam@egestashendreritnequecom   \n",
       "25         Maecenas@sociisnatoquepenatibuscom   \n",
       "4          Namnullamagna@massaIntegervitaecom   \n",
       "1   ullamcorperDuiscursus@vehiculaetrutrumedu   \n",
       "2               ametanteVivamus@arcuacorcicom   \n",
       "..                                        ...   \n",
       "16                    Duis@dolorvitaedoloredu   \n",
       "17     vitaeposuere@nonummyultriciesornarecom   \n",
       "18       bibendumfermentummetus@Donecfelisedu   \n",
       "19             venenatis@massaIntegervitaeorg   \n",
       "20         ipsumdolorsit@Maecenasmalesuadaedu   \n",
       "\n",
       "                             Company  \n",
       "0         Aliquam Nec Enim Institute  \n",
       "25                     Elementum Inc  \n",
       "4                Volutpat Nulla Corp  \n",
       "1         Turpis Egestas Aliquam Ltd  \n",
       "2             A Malesuada Associates  \n",
       "..                               ...  \n",
       "16                 Neque Sed Limited  \n",
       "17                   Ante Ipsum Corp  \n",
       "18           Netus Et Malesuada Corp  \n",
       "19         Semper Dui Lectus Limited  \n",
       "20  Magnis Dis Parturient Associates  \n",
       "\n",
       "[99 rows x 6 columns]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# voila\n",
    "result_df_ex3.sort_values('Updated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mic drop\n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = open(\"PeopleTrainingDateUpdate.csv\")\n",
    "\n",
    "file2.readline()\n",
    "\n",
    "# split into seperate strings in a list by comma, remove unnecessary characters\n",
    "entry_list = []\n",
    "for line in file2:\n",
    "    items = line.split(\",\")\n",
    "    stripped_items = []\n",
    "    for i in items:\n",
    "        stripped_items.append(i.replace('\"', \"\").replace(\"\\n\", \"\").replace(\".\", \"\").lstrip(\" \"))\n",
    "    entry_list.append(stripped_items)\n",
    "\n",
    "\n",
    "#visual check - different order: Updated, email+id, title, surname, first_name and initial\n",
    "entry_list\n",
    "\n",
    "# check for consistency by length - all have same number of items\n",
    "#  but 1 less than first file as email and id are not comma seperated\n",
    "length_list = []\n",
    "for l in entry_list:\n",
    "    x = len(l)\n",
    "    length_list.append(x)\n",
    "\n",
    "length_list\n",
    "\n",
    "for l in entry_list:\n",
    "    email_id = l[1].split(\" \")\n",
    "    l.remove(l[1])\n",
    "    l.extend(email_id)\n",
    "    \n",
    "    \n",
    "\n",
    "# order is now: Updated, title, surname, first_name, company, email, id\n",
    "entry_list\n",
    "\n",
    "# use a for loop to create lists for each column\n",
    "title = []\n",
    "first_name = []\n",
    "surname = []\n",
    "i_d = []\n",
    "email = []\n",
    "company = []\n",
    "updated = []\n",
    "for l in entry_list:\n",
    "    title.append(l[1])\n",
    "    first_name.append(l[3])\n",
    "    surname.append(l[2])\n",
    "    i_d.append(l[6])\n",
    "    email.append(l[5])\n",
    "    company.append(l[4])\n",
    "    updated.append(l[0])\n",
    "\n",
    "# list comprehension to create one name variable from surname and first_name\n",
    "name = [x + \", \" + y for x,y in zip(surname, first_name)]\n",
    "\n",
    "# dict following same order as result_df_ex2, which this incoming data will be merged with\n",
    "title_column_dict_rearr = {cols[5]: updated, cols[0]: title, cols[1]: name, cols[2]: i_d, cols[3]: email, cols[4]: company}\n",
    "\n",
    "# create_dataframe\n",
    "df_ex3 = pd.DataFrame(title_column_dict_rearr)\n",
    "\n",
    "# merge with existing df\n",
    "dfs_to_merge = [result_df_ex2, df_ex3]\n",
    "result_df_ex3 = pd.concat(dfs_to_merge)\n",
    "\n",
    "# convert updated to datetime for sorting\n",
    "result_df_ex3['Updated'] = pd.to_datetime(result_df_ex3['Updated'])\n",
    "\n",
    "# voila\n",
    "result_df_ex3.sort_values('Updated')\n",
    "\n",
    "# mic drop\n",
    "file2.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
